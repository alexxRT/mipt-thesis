\section{Описание практической части}
\label{sec:Chapter3} \index{Chapter3}

\subsection{Профилирование и сериализация}

Одной из первых и ключевых задач практической части работы стало унифицирование формата полученного профиля выполнения.
Ввиду разнообразия существующих решений для профилирования и в целях соответствия поставленным задачам, наиболее подходящим инструментом трассировки исполняемых операций был выбран \textbf{TensorFlow Profiler (TF Profiler)}.
Он предоставляет средства для отслеживания времени выполнения высокоуровневых операций, что позволяет с относительной лёгкостью сопоставить полученные профили с операциями графа MLIR.

Промежуточным этапом на пути к этому стало создание собственного представления трассы операций в виде направленного ациклического графа (DAG, от англ. Directed Acyclic Graph).

\subsubsection{Выходной формат профиля и возможности профилировщика}

Для получения профиля была разработана простая программа на языке Python, выполняющая обучение модели.
Структура и логика самой модели не являются предметом данного исследования и далее рассматриваться не будут.
Ключевым аспектом является формат сохраняемых данных.

Профилировщик TensorFlow предоставляет возможность настройки через специальную структуру параметров — \textbf{ProfilerOptions}:

\begin{lstlisting}[caption={Опции профилирования \textbf{TF Profiler}}]
options = tf.profiler.experimental.ProfilerOptions(
    host_tracer_level=2,
    python_tracer_level=1,
    device_tracer_level=1
)
\end{lstlisting}

Значения уровней профилирования соответствуют степени детализации: чем выше значение, тем более подробные данные собирает профилировщик.
В рамках данной работы были задействованы следующие классы событий:

\begin{itemize}
\item Трассировщик хоста — события, связанные с планировщиком операций и потоками исполнения на уровне хост-системы.
\item Трассировщик Python — вызовы функций на языке Python и высокоуровневые операции TensorFlow.
\item Трассировщик устройства — данные об использовании памяти, загрузке CPU и других характеристиках вычислительных устройств.
\end{itemize}

Результатом работы профилировщика является двоичный формат на основе технологии Protocol Buffers, разработанной компанией Google.
TensorFlow предоставляет средства для преобразования файлов \texttt{.pb} в человекочитаемый формат \texttt{.json}.
Полученный файл представляет собой последовательность событий, каждое из которых включает как временные характеристики, так и ссылку на метаданные.

\noindent
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[caption={Данные события \textbf{TF Profiler}}]
{
"metadata_id": "1327",
"offset_ps": "120000",
"duration_ps": "20000000"
},
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[caption={Метаданные события \textbf{TF Profiler}}]
{
"id": "1327",
"name": "$tensorflow.python._pywrap_tfe TFE_Py_TapeSetRecordOperation"
},
\end{lstlisting}
\end{minipage}

Путём варьирования уровней детализации удалось добиться включения в профиль названий интересующих операций, что впоследствии использовалось для аннотирования.
Следующим этапом стало связывание событий с метаданными, а также построение DAG на основе временных характеристик (времени начала и продолжительности операций).

\subsubsection{DAG: построение и сериализация}

Для представления операций в виде графа был разработан собственный класс \textbf{MlirGraph}, вершины которого содержат агрегированную информацию об операциях.
Логика построения графа реализована в модуле \textbf{traceReader.py}, предоставляющем также интерфейс командной строки (CLI) для удобства использования.

Поскольку каждое событие содержит время начала и длительность, оно может быть представлено как временной отрезок.
При добавлении события в граф осуществляется проверка на наличие перекрытия с уже добавленными отрезками.
Такие перекрытия определяют уровни графа: события, попавшие на один уровень, интерпретируются как потенциально параллельные, тогда как переход на следующий уровень отражает зависимость во времени исполнения операций.

Пример вызова утилиты:

\begin{lstlisting}[caption={Пример использования программы traceReader.py}]
python3 traceReader.py --path-to-trace trace.pb(.json) --store-output mlir_graph.json
\end{lstlisting}

Результатом работы является сериализованный граф, содержащий следующую информацию:

\noindent
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[caption={Формат вершины MLIR-графа}]
{
"name": "$tensorflow.python._pywrap_tfe TFE_DeleteExecutor",
"ts": 37501000000,
"duration": 2000000,
"id": 483,
"adj": [484, 485, 486, 487]
},
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[caption={Формат ребра MLIR-графа}]
{
    "edgeFrom": 483,
    "edgeTo": 484
},
{
    "edgeFrom": 483,
    "edgeTo": 485
}
\end{lstlisting}
\end{minipage}

Помимо времени выполнения и идентификатора, каждая вершина включает имя операции и список смежных узлов (смежность указывает на логические или временные зависимости).
Такой граф может быть повторно считан из файла, а при необходимости — преобразован в формат \textbf{NetworkX} для последующего анализа и разработки алгоритмов трансформации графов.

\subsection{Аннотирование операций}

Классовая организация, высокая модульность и гибкая архитектура MLIR делают возможным простое расширение функциональности существующих диалектов. В рамках данной работы была реализована система аннотирования операций диалекта \texttt{tf} (TensorFlow) в соответствии с архитектурными принципами MLIR.

\subsubsection{Интерфейс для работы с аннотациями}

В качестве основного подхода была выбрана реализация интерфейса непосредственно внутри операций. Такой метод не привязан к конкретному диалекту и, при необходимости, может быть легко адаптирован для других диалектов в будущем.

Фреймворк \textbf{TensorFlow} использует систему \textbf{TableGen} для генерации заголовочных файлов, определения классов, описания операций и трейтов. TableGen позволяет избежать дублирования C++-кода, предоставляя шаблонный, компактный способ описания, на основе которого во время компиляции автоматически создаются соответствующие заголовочные файлы.

Ниже представлено описание разработанного интерфейса аннотирования на языке TableGen:

\begin{lstlisting}[caption={Описание интерфейса аннотирования на языке TableGen}]
def TF_ProfilerAnnotationsInterface : OpInterface<"ProfilerAnnotationsInterface"> {
let description = [{Methods to get/attach profiler data as annotations}];
let methods = [
    InterfaceMethod<
        /*retTy=*/"void",
        /*methodName=*/"AttachProfilerData",
        /*args*/(ins "const ProfilerData&":$data)
    >,
    ...
];
}
\end{lstlisting}

Для краткости изложения методы \texttt{GetProfilerData} и \texttt{HasProfilerData} в данном фрагменте опущены, однако они также были реализованы.

В качестве аннотаций было решено использовать временные характеристики операций: время начала и длительность исполнения.

\subsubsection{Трейты: назначение и применение}

\textbf{Трейты} в MLIR представляют собой механизм, позволяющий присваивать операциям определённые свойства. Эти свойства могут использоваться, например, для проверки типов операндов: если операнды не удовлетворяют требованиям трейта, они не могут быть переданы соответствующей операции. Трейты также обеспечивают связь между операциями и интерфейсами, позволяя гарантировать их совместимость на этапе компиляции.

В рассматриваемой работе трейты используются для реализации интерфейса аннотирования вне тела самих операций. Это позволяет значительно сократить количество зависимостей в коде и способствует модульной повторной используемости компонентов, аналогично паттерну \textit{dependency injection}, хорошо известному по экосистеме Java (например, в Spring Framework через механизмы Beans).

Трейты реализуются на основе паттерна \textbf{CRTP} (Curiously Recurring Template Pattern), обеспечивающего статический полиморфизм. Базовый шаблонный класс принимает в качестве параметра дочерний класс, что позволяет ему вызывать методы, определённые в этом дочернем классе. Ниже приведён минимальный пример реализации данного паттерна:

\begin{lstlisting}[caption={Демонстрация принципа CRTP}]
template <class T>
struct Base {
    void interface() {
        // ...
        static_cast<T*>(this)->implementation();
        // ...
    }

    static void static_func() {
        // ...
        T::static_sub_func();
        // ...
    }
};

struct Derived : public Base<Derived> {
    void implementation();
    static void static_sub_func();
};
\end{lstlisting}

На основе вышеуказанного подхода был реализован собственный трейт, обеспечивающий поддержку интерфейса аннотирования:

\begin{lstlisting}[caption={Трейт аннотирования операций MLIR}]
template <typename ConcreteType>
class ProfileAnnotation : public TraitBase<ConcreteType, ProfileAnnotation> {
    public:
        // Implements methods required for TF_ProfilerAnnotationsInterface
        void AttachProfilerData(const ProfilerData& data);

        ProfilerData GetProfilerData();

        bool HasProfilerData();
};
\end{lstlisting}

В качестве результата разработки, ниже приведена реализация метода \texttt{AttachProfilerData}, предназначенного для присвоения аннотаций операции:

\begin{lstlisting}[caption={Реализация метода AttachProfilerData}]
void AttachProfilerData(const ProfilerData& data) {
    Operation* op = this->getOperation();
    MLIRContext* context = op->getContext();

    Builder builder(context);

    auto tsAttr = builder.getI64IntegerAttr(data.timestamp);
    auto durationAttr = builder.getI64IntegerAttr(data.duration);

    NamedAttribute attrs[] = {
        builder.getNamedAttr("ts", tsAttr),
        builder.getNamedAttr("dur", durationAttr)
    };

    auto dictAttr = DictionaryAttr::get(context, attrs);
    op->setAttr("profiler_data", dictAttr);
}
\end{lstlisting}

По средствам описанного паттерна был реализован расширяемый интерфейс аннотирования операций.
В дальнейшем, трейт может быть использован с любой операцией TensorFlow, представляющей интерес для анализа трансформаций графа.

\subsubsection{Регистрация проходов и создание pipeline для аннотирования операций}

Для того чтобы аннотации, добавленные в операции, появились в генерируемом промежуточном представлении (IR), необходимо зарегистрировать собственный проход компиляции (далее — pass) в менеджере проходов (pass manager).
Этот механизм позволяет эффективно обрабатывать и изменять IR на различных этапах компиляции.

В рамках данной работы было принято решение вынести изменения IR, касающиеся профилирования и оптимизации на основе профиля исполнения (PGO, Profile-Guided Optimization), в отдельную последовательность проходов, которая будет называться pipeline.
Это решение имеет несколько ключевых преимуществ. Во-первых, оно помогает организовать оптимизации в логическую структуру, разделяя их по категориям. Во-вторых, такой подход обеспечивает гибкость в добавлении новых проходов и оптимизаций, которые могут быть реализованы в будущем для конкретных задач машинного обучения.

Создание и регистрация pass-ов и pipeline в MLIR схожи с подходом, используемым в LLVM, что делает систему гибкой и хорошо документированной.
Разработка и настройка этих механизмов является важной частью работы по интеграции аннотирования в процесс компиляции.

В рамках задачи по созданию pass-ов и pipeline были выполнены следующие шаги:

\begin{itemize}
\item Реализация pass-а для рекурсивного прохода по операциям и добавления аннотаций.
\item Регистрация pipeline, включающего на данный момент только проход для аннотирования операций.
\end{itemize}

Ниже представлено объяснение каждого из этих шагов в контексте выполнения задач.

\textbf{Pass} — это ключевая концепция в MLIR и LLVM, которая представляет собой отдельный шаг обработки, который может изменять, оптимизировать или анализировать промежуточное представление (IR).
 В данном случае, основной задачей pass-а является рекурсивный обход операций и добавление аннотированных данных о времени выполнения.

Процесс рекурсивного прохода по операциям включает следующие этапы:

\begin{enumerate}
    \item Программы, описанные в виде IR, представляют собой граф операций, где каждая операция может содержать множество подопераций (дочерних операций).
    \item Pass рекурсивно проходит по всем операциям и их подоперациям, извлекая и присваивая аннотированные данные (например, время начала и продолжительности выполнения).
    \item На каждой операции добавляются метаданные, которые затем сохраняются в IR и могут быть использованы для анализа.
\end{enumerate}

Пример кода для реализации такого pass-а может выглядеть следующим образом:

\newpage

\begin{lstlisting}[caption={Проход аннотирования операций}]
void AnnotateOperationsProfilePass::runOnOperation() {
  ModuleOp op = getOperation();

  op.walk([&](Operation* nestedOp) {
    if (nestedOp->getDialect() &&
        nestedOp->getDialect()->getNamespace() == "tf") {
        if (nestedOp->hasTrait<ProfileAnnotation>()) {
            ProfilerData data(0, 0);
            readProfilerData(&data, nestedOp);
            nestedOp->AttachProfilerData(data);
        }
    }
  });
}
\end{lstlisting}


Вторым важным шагом является создание и регистрация \textbf{pipeline}, который будет включать все проходы (pass-ы), необходимые для обработки программы.
\textbf{Pipeline} — это последовательность проходов, которая выполняется в заданном порядке, позволяя эффективно обрабатывать код.
В данной работе pipeline был сконфигурирован для включения только одного pass-а, отвечающего за аннотирование операций.
Это позволяет организовать обработку профиля таким образом, что на следующем этапе можно легко добавить новые проходы, например, для анализа или оптимизации на основе собранных данных.

Пример кода для регистрации pipeline:

\begin{lstlisting}[caption={Регистрация PGO pipeline-а}]
void CreateTFProfileGuidedPipeline(OpPassManager &pm,
                              const ProfileGuidedPipelineOptions &options) {
    if (options.enable_profile) {
        OpPassManager &module_op_pm = pm.nest<ModuleOp>();
        module_op_pm.addPass(TF::CreateAnnotateOperationsProfilePass(options.path_to_profile));
        // perform here profile guided transformations
    }
}
\end{lstlisting}


Таким образом, была реализована модульная и расширяемая система аннотирования операций диалекта TensorFlow, использующая архитектурные возможности MLIR: интерфейсы, трейты и шаблонное программирование на C++.

\newpage

\subsection{Визуализация DAG}

В рамках данной работы был разработан инструмент для визуального анализа сериализованного направленного ациклического графа (DAG), реализованный в виде модуля \textbf{plotGraph.py}.
Данный модуль принимает на вход сериализованный файл в формате JSON, содержащий описание DAG, который является результатом работы компонента \texttt{traceReader.py}.
Кроме того, в коде было реализовано разделение вершин графа с использованием цветовой кодировки в зависимости от времени выполнения операций, связанных с функциями-вершинами DAG.
В возможности модуля входит также сохранение графа в следующих форматах: \textbf{.graphml}, \textbf{.dot}, \textbf{.svg}.

Основным преимуществом предложенного решения является возможность визуализации и детального анализа результатов работы TensorFlow Profiler.
Иными словами, в зависимости от выбора уровня профилирования, возможно как изменять, так и расширять область визуального анализа.

К примеру, при настройке уровней профилирования следующим образом:

\begin{lstlisting}[caption={Регистрация PGO pipeline-а}]
options = tf.profiler.experimental.ProfilerOptions(
    host_tracer_level=0,
    python_tracer_level=1,
    device_tracer_level=0
)
\end{lstlisting}

можно получить граф вызовов функций, реализованных на языке Python.

Пример вызова утилиты:

\begin{lstlisting}[caption={Пример использования программы plotGraph.py}]
python3 plotGraph.py (-s) --path-to-mlir-graph mlir-dag.json -o out.svg
\end{lstlisting}

Пример визуализации, полученной в результате работы утилиты:

\begin{figure}[h]
\centering
\begin{overpic}[width=0.8\textwidth]{python-call-graph.png}
\end{overpic}
\caption{Пример результата работы программы plotGraph.py. Граф вызовов функций Python}
\end{figure}


\newpage
