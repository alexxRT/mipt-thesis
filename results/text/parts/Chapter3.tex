\section{Описание практической части}
\label{sec:Chapter3} \index{Chapter3}

\subsection{Профилирование и сериализация}

Одной из первых и ключевых задач практической части работы стало унифицирование формата полученного профиля выполнения.
Ввиду разнообразия существующих решений для профилирования и в целях соответствия поставленным задачам, наиболее подходящим инструментом трассировки исполняемых операций был выбран \textbf{TensorFlow Profiler (TF Profiler)}.
Он предоставляет средства для отслеживания времени выполнения высокоуровневых операций, что позволяет с относительной лёгкостью сопоставить полученные профили с операциями графа MLIR.

Промежуточным этапом на пути к этому стало создание собственного представления трассы операций в виде направленного ациклического графа (DAG, от англ. Directed Acyclic Graph).

\subsubsection{Выходной формат профиля и возможности профилировщика}

Для получения профиля была разработана простая программа на языке Python, выполняющая обучение модели.
Структура и логика самой модели не являются предметом данного исследования и далее рассматриваться не будут.
Ключевым аспектом является формат сохраняемых данных.

Профилировщик TensorFlow предоставляет возможность настройки через специальную структуру параметров — \textbf{ProfilerOptions}:

\begin{lstlisting}[caption={Опции профилирования \textbf{TF Profiler}}]
options = tf.profiler.experimental.ProfilerOptions(
host_tracer_level=2,
python_tracer_level=1,
device_tracer_level=1
)
\end{lstlisting}

Значения уровней профилирования соответствуют степени детализации: чем выше значение, тем более подробные данные собирает профилировщик.
В рамках данной работы были задействованы следующие классы событий:

\begin{itemize}
\item Трассировщик хоста — события, связанные с планировщиком операций и потоками исполнения на уровне хост-системы.
\item Трассировщик Python — вызовы функций на языке Python и высокоуровневые операции TensorFlow.
\item Трассировщик устройства — данные об использовании памяти, загрузке CPU и других характеристиках вычислительных устройств.
\end{itemize}

Результатом работы профилировщика является двоичный формат на основе технологии Protocol Buffers, разработанной компанией Google.
TensorFlow предоставляет средства для преобразования файлов \texttt{.pb} в человекочитаемый формат \texttt{.json}.
Полученный файл представляет собой последовательность событий, каждое из которых включает как временные характеристики, так и ссылку на метаданные.

\noindent
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[caption={Данные события \textbf{TF Profiler}}]
{
"metadata_id": "1327",
"offset_ps": "120000",
"duration_ps": "20000000"
},
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[caption={Метаданные события \textbf{TF Profiler}}]
{
"id": "1327",
"name": "$tensorflow.python._pywrap_tfe TFE_Py_TapeSetRecordOperation"
},
\end{lstlisting}
\end{minipage}

Путём варьирования уровней детализации удалось добиться включения в профиль названий интересующих операций, что впоследствии использовалось для аннотирования.
Следующим этапом стало связывание событий с метаданными, а также построение DAG на основе временных характеристик (времени начала и продолжительности операций).

\subsubsection{DAG: построение и сериализация}

Для представления операций в виде графа был разработан собственный класс \textbf{MlirGraph}, вершины которого содержат агрегированную информацию об операциях.
Логика построения графа реализована в модуле \textbf{traceReader.py}, предоставляющем также интерфейс командной строки (CLI) для удобства использования.

Поскольку каждое событие содержит время начала и длительность, оно может быть представлено как временной отрезок.
При добавлении события в граф осуществляется проверка на наличие перекрытия с уже добавленными отрезками.
Такие перекрытия определяют уровни графа: события, попавшие на один уровень, интерпретируются как потенциально параллельные, тогда как переход на следующий уровень отражает зависимость во времени исполнения операций.

Пример вызова утилиты:

\begin{lstlisting}[caption={Пример использования программы traceReader.py}]
python3 traceReader.py --path-to-trace trace.pb(.json) --store-output mlir_graph.json
\end{lstlisting}

Результатом работы является сериализованный граф, содержащий следующую информацию:

\noindent
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[caption={Формат вершины MLIR-графа}]
{
"name": "$tensorflow.python._pywrap_tfe TFE_DeleteExecutor",
"ts": 37501000000,
"duration": 2000000,
"id": 483,
"adj": [484, 485, 486, 487]
},
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{0.48\textwidth}
\begin{lstlisting}[caption={Формат ребра MLIR-графа}]
{
    "edgeFrom": 483,
    "edgeTo": 484
},
{
    "edgeFrom": 483,
    "edgeTo": 485
}
\end{lstlisting}
\end{minipage}

Помимо времени выполнения и идентификатора, каждая вершина включает имя операции и список смежных узлов (смежность указывает на логические или временные зависимости).
Такой граф может быть повторно считан из файла, а при необходимости — преобразован в формат \textbf{NetworkX} для последующего анализа и разработки алгоритмов трансформации графов.

\subsection{Аннотирование операций}

Классовая организация, высокая модульность и гибкая архитектура MLIR делают возможным простое расширение функциональности существующих диалектов. В рамках данной работы была реализована система аннотирования операций диалекта \texttt{tf} (TensorFlow) в соответствии с архитектурными принципами MLIR.

\subsubsection{Интерфейс для работы с аннотациями}

В качестве основного подхода была выбрана реализация интерфейса непосредственно внутри операций. Такой метод не привязан к конкретному диалекту и, при необходимости, может быть легко адаптирован для других диалектов в будущем.

Фреймворк \textbf{TensorFlow} использует систему \textbf{TableGen} для генерации заголовочных файлов, определения классов, описания операций и трейтов. TableGen позволяет избежать дублирования C++-кода, предоставляя шаблонный, компактный способ описания, на основе которого во время компиляции автоматически создаются соответствующие заголовочные файлы.

Ниже представлено описание разработанного интерфейса аннотирования на языке TableGen:

\begin{lstlisting}[caption={Описание интерфейса аннотирования на языке TableGen}]
def TF_ProfilerAnnotationsInterface : OpInterface<"ProfilerAnnotationsInterface"> {
let description = [{Methods to get/attach profiler data as annotations}];
let methods = [
    InterfaceMethod<
        /*retTy=*/"void",
        /*methodName=*/"AttachProfilerData",
        /*args*/(ins "const ProfilerData&":$data)
    >,
    ...
];
}
\end{lstlisting}

Для краткости изложения методы \texttt{GetProfilerData} и \texttt{HasProfilerData} в данном фрагменте опущены, однако они также были реализованы.

В качестве аннотаций было решено использовать временные характеристики операций: время начала и длительность исполнения.

\subsubsection{Трейты: назначение и применение}

\textbf{Трейты} в MLIR представляют собой механизм, позволяющий присваивать операциям определённые свойства. Эти свойства могут использоваться, например, для проверки типов операндов: если операнды не удовлетворяют требованиям трейта, они не могут быть переданы соответствующей операции. Трейты также обеспечивают связь между операциями и интерфейсами, позволяя гарантировать их совместимость на этапе компиляции.

В рассматриваемой работе трейты используются для реализации интерфейса аннотирования вне тела самих операций. Это позволяет значительно сократить количество зависимостей в коде и способствует модульной повторной используемости компонентов, аналогично паттерну \textit{dependency injection}, хорошо известному по экосистеме Java (например, в Spring Framework через механизмы Beans).

Трейты реализуются на основе паттерна \textbf{CRTP} (Curiously Recurring Template Pattern), обеспечивающего статический полиморфизм. Базовый шаблонный класс принимает в качестве параметра дочерний класс, что позволяет ему вызывать методы, определённые в этом дочернем классе. Ниже приведён минимальный пример реализации данного паттерна:

\begin{lstlisting}[caption={Демонстрация принципа CRTP}]
template <class T>
struct Base {
    void interface() {
        // ...
        static_cast<T*>(this)->implementation();
        // ...
    }

    static void static_func() {
        // ...
        T::static_sub_func();
        // ...
    }
};

struct Derived : public Base<Derived> {
    void implementation();
    static void static_sub_func();
};
\end{lstlisting}

На основе вышеуказанного подхода был реализован собственный трейт, обеспечивающий поддержку интерфейса аннотирования:

\begin{lstlisting}[caption={Трейт аннотирования операций MLIR}]
template <typename ConcreteType>
class ProfileAnnotation : public TraitBase<ConcreteType, ProfileAnnotation> {
    public:
        // Implements methods required for TF_ProfilerAnnotationsInterface
        void AttachProfilerData(const ProfilerData& data);

        ProfilerData GetProfilerData();

        bool HasProfilerData();
};
\end{lstlisting}

В качестве результата разработки, ниже приведена реализация метода \texttt{AttachProfilerData}, предназначенного для присвоения аннотаций операции:

\begin{lstlisting}[caption={Реализация метода AttachProfilerData}]
void AttachProfilerData(const ProfilerData& data) {
    Operation* op = this->getOperation();
    MLIRContext* context = op->getContext();

    Builder builder(context);

    auto tsAttr = builder.getI64IntegerAttr(data.timestamp);
    auto durationAttr = builder.getI64IntegerAttr(data.duration);

    NamedAttribute attrs[] = {
        builder.getNamedAttr("ts", tsAttr),
        builder.getNamedAttr("dur", durationAttr)
    };

    auto dictAttr = DictionaryAttr::get(context, attrs);
    op->setAttr("profiler_data", dictAttr);
}
\end{lstlisting}

Таким образом, была реализована модульная и расширяемая система аннотирования операций диалекта TensorFlow, использующая архитектурные возможности MLIR: интерфейсы, трейты и шаблонное программирование на C++.

\newpage
