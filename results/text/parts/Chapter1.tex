\section{Постановка задачи}
\label{sec:Chapter1} \index{Chapter1}

Необходимость вышеописанного инстремента в сущности очевидна, его наличие позволило бы детально инспектировать программы машинного обучения и быстро находить места, требующие оптимизаций.
В особенности с появлением новых вычислительных ускорителей и альтернативных архитектур очень актуальным становится вопрос об оптимизациях для исполнения на конкретных устройствах.
Это позволило бы значительно ускорить предкомпилированные модели, использующие оптимизации основанные на их же профиле исполнения.

Чтобы достичь этой цели, сформулируем задачу решаемую в рамках данной дипломной работы:

\begin{quote}
\textit{Разработка средства автоматического аннотирования промежуточного представления программ на основе профиля исполнения в рамках инфраструктуры MLIR}
\end{quote}

Поставлненная задача требует дополнительных пояснения, тк не может быть решена исходя из начальной формулировки.
Постараемся разбить задачу на более мелкие части и зададимся целью подробного описания их взаимосвязи.
Будем ранжировать также подзадачи в порядке убывающей важности, так чтобы сохранять акцент на поставленной задаче.
Рассмотрим каждую из сформулированных подзадач в отдельности:

\subsection{Расширение существующего диалекта/ов}

MLIR предоставляет широкие возможности как для создания собственных диалектов, так и для расширения уже существующих.
Однако, в отличие от классических объектно-ориентированных подходов, в MLIR отсутствует механизм прямого наследования диалектов, поскольку архитектура системы строится на принципах композиции.

Цель данной работы — получение расширенного промежуточного представления, способного не только сохранять профиль исполнения, но и обеспечивать доступ к этим данным на любом уровне абстракции после понижения (lowering).

Рассматривался подход создания обёрточного (proxy) диалекта, однако он оказался неприемлемым по ряду причин. Такой диалект создает дополнительный уровень представления, где каждый узел графа должен содержать информацию о соответствии операциям различных существующих диалектов.
Это потребовало бы ручного или автоматического "протягивания" метаданных через весь процесс lowering'а, что существенно усложняет архитектуру и увеличивает техническую сложность без значимых преимуществ.
По этой причине такой путь был отвергнут.

В данной работе основным и выбранным для реализации способом является создание интерфейса для основных операций.
Этот подход не привязан к конкретному диалекту, а лишь служит инструментом в рамках контекста выбранных для профилирования операций.
Небольшой участок кода поможет лучше понять структуру предлагаемого подхода:

\begin{lstlisting}[caption={Структура реализуемого интерфейса}]

class ProfiledOpInterface : public OpInterface<ProfiledOpInterface> {
    public:
    void attachProfileData(ProfileData data);
    ProfileData getProfileData();
    bool hasProfileData();
};

\end{lstlisting}

Важно подчеркнуть, что данный подход не накладывает жестких ограничений на целевой (инспектируемый) диалект и может быть реализован на произвольном уровне абстракции, соответствующем интересам анализа.
Кроме того, описанный паттерн органично интегрируется в модульную архитектуру MLIR, не нарушая ее принципов и не внося дополнительных межмодульных зависимостей.
Подробнее о конкретной реализации интерфейса и служебных структур в контексте аннотируемых метаданных можно ознакомться в секции~\nameref{sec:Chapter3}.

\subsection{Получение формата данных профилирования}

Следующей и не менее важной подзадачей является получение унифицированного формата данных после работы профилировщика.
В этой работе предлагается расширить возможности использования привычного для PGO оптимизаций в LLVM профилировщика perf.
На сегодняшний день интересующие нас фреймворки \textbf{Tensorflow}, \textbf{ONNX} и \textbf{PyTorch} предлагают готовые решения для сбора различной статистики выполнения высокоуровневых операций.

Типичный кусок кода написанный для сбора профиля исполнения модели:

\begin{lstlisting}[caption={Получение профиля с помощью утилиты фреймворка \textbf{Tensorflow}}]
    # Profiling options set
    options = tf.profiler.experimental.ProfilerOptions(
        ...
    )
    # Profiling start
    tf.profiler.experimental.start(log_dir, options=options)

    try:
        # Model run code
                ...
    finally:
        # Profiling stop
        tf.profiler.experimental.stop()
\end{lstlisting}

Согласно документации tensorflow-profile-plugin [см источник \cite{tf_profiler}] в настоящее время поддерживается следующий список устройств, в соответствующей конфигурации:

\begin{figure}[h]
\centering
\begin{overpic}[width=0.8\textwidth]{profiler-platforms.png}
\end{overpic}
\caption{Список поддерживаемых устройств и режимов работы профилировщика \textbf{TensorFlow}.}
\end{figure}

В рамках данной работы в качестве целевой платформы предлагается использовать \textbf{CPU}.
Важно отметить, что такой выбор не накладывает ограничений на область применимости разрабатываемого инструмента профилирования.

С появлением поддержки новых устройств в существующих профилировщиках, либо при использовании альтернативных решений, разработанных для отдельных устройств (например, Huawei NPU Ascend), потребуется изменить лишь этап предобработки входных данных, но не саму архитектуру обработки и анализа.
Такой уровень абстракции достигается за счёт использования промежуточного формата представления данных профиля в виде сериализованного файла \texttt{.json}.

Преимущества этого подхода, а также его реализация, будут подробно рассмотрены в секции~\nameref{sec:Chapter3}.

Последним замечанием к описанию подзадачи получения формата данных профиля будет представлен список возможностей \textbf{Tensorflow}.

\begin{itemize}
    \item Анализатор конвейера данных - анализирует эффективность загрузки и предобработки данных, помогает выявить узкие места в подаче данных в модель
    \item Статистика TensorFlow - собирает и отображает статистику выполнения операций, показывает время работы каждой операции и использование ресурсов
    \item Просмотрщик трассировки - визуализирует временную шкалу выполнения операций на процессоре и GPU, позволяет увидеть параллельность и простои
    \item Инструмент профилирования памяти - отслеживает использование памяти GPU и RAM, помогает оптимизировать потребление памяти и избежать переполнения
\end{itemize}

Каждый инструмент решает конкретные задачи оптимизации: от анализа загрузки данных до мониторинга распределенного обучения.
Второй и третий пункты из списка возможностей будут активно использованы в рамках выполнения практической части дипломной работы.

Подробнее о возможностях \texttt{TensorflowProfiler} и формате выходных данных будет рассказано в секции ~\nameref{sec:Chapter2}.

\subsection{Визуализация и анализ}

После получения формата профилированных данных и создания интерфейса взаимодействия с ними в рамках операций MLIR, формируется подзадача визуализации результатов профилирования на итоговом графе исполнения.
Данный этап является значимым, поскольку качество визуального представления профиля критически важно по следующим причинам:

\begin{itemize}
\item обоснование аналитических выводов;
\item обеспечение наглядности и интерпретируемости результатов;
\item возможность последующего применения визуализации при разработке оптимизаций.
\end{itemize}

Примером возможных преобразований могут являться трансформации графа, основанные на длительности выполнения операций.
Графическое представление последовательности вычислений в виде ориентированного графа с аннотациями, содержащими данные профиля, позволяет локализовать узлы с наибольшей нагрузкой.

В качестве иллюстрации представлен условный граф, демонстрирующий целевой формат визуализации:

\begin{figure}[h]
\centering
\begin{overpic}[width=\textwidth]{example.png}
\end{overpic}
\caption{Условный пример визуализации профиля исполнения.}
\end{figure}

Представленные в приложениях визуализации (см. секцию~\nameref{sec:Chapter5}) позволяют выполнить оценку полноты и корректности реализованного инструмента.
Кроме того, на основе профиля реальной модели выделяются участки, требующие приоритетного применения оптимизаций.

\newpage
